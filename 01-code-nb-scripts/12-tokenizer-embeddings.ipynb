{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56a0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tiktoken==0.12.0 pandas==2.2.2 numpy==2.0.2 torch==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbab09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "Learning never stops | ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ | Â≠¶„Å≥„ÅØÊ≠¢„Åæ„Çâ„Å™„ÅÑ üòä\n",
      "\n",
      "Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-06dbe083-e732-4767-b45e-4b3e068c5656\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vocab size</th>\n",
       "      <th>Token count</th>\n",
       "      <th>Round-trip OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-2</td>\n",
       "      <td>50257</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-3</td>\n",
       "      <td>50281</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>100277</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>200019</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06dbe083-e732-4767-b45e-4b3e068c5656')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-06dbe083-e732-4767-b45e-4b3e068c5656 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-06dbe083-e732-4767-b45e-4b3e068c5656');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    Model  Vocab size  Token count  Round-trip OK\n",
       "0   GPT-2       50257           51           True\n",
       "1   GPT-3       50281           51           True\n",
       "2   GPT-4      100277           38           True\n",
       "3  GPT-4o      200019           20           True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token piece comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2fbf8832-c6e2-483d-869e-0ac2f26f5ca1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx</th>\n",
       "      <th>GPT-2</th>\n",
       "      <th>GPT-3</th>\n",
       "      <th>GPT-4</th>\n",
       "      <th>GPT-4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "      <td>'Learning'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>' never'</td>\n",
       "      <td>' never'</td>\n",
       "      <td>' never'</td>\n",
       "      <td>' never'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>49</td>\n",
       "      <td>' ÔøΩ'</td>\n",
       "      <td>' ÔøΩ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>50</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>50</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>50</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>50</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td>'ÔøΩ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows √ó 5 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fbf8832-c6e2-483d-869e-0ac2f26f5ca1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2fbf8832-c6e2-483d-869e-0ac2f26f5ca1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2fbf8832-c6e2-483d-869e-0ac2f26f5ca1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Idx       GPT-2       GPT-3       GPT-4      GPT-4o\n",
       "0      0  'Learning'  'Learning'  'Learning'  'Learning'\n",
       "1      0  'Learning'  'Learning'  'Learning'  'Learning'\n",
       "2      0  'Learning'  'Learning'  'Learning'  'Learning'\n",
       "3      0  'Learning'  'Learning'  'Learning'  'Learning'\n",
       "4      1    ' never'    ' never'    ' never'    ' never'\n",
       "..   ...         ...         ...         ...         ...\n",
       "199   49        ' ÔøΩ'        ' ÔøΩ'                        \n",
       "200   50         'ÔøΩ'         'ÔøΩ'                        \n",
       "201   50         'ÔøΩ'         'ÔøΩ'                        \n",
       "202   50         'ÔøΩ'         'ÔøΩ'                        \n",
       "203   50         'ÔøΩ'         'ÔøΩ'                        \n",
       "\n",
       "[204 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Encodings\n",
    "encodings = {\n",
    "    \"GPT-2\": tiktoken.get_encoding(\"gpt2\"),\n",
    "    \"GPT-3\": tiktoken.get_encoding(\"p50k_base\"),\n",
    "    \"GPT-4\": tiktoken.get_encoding(\"cl100k_base\"),\n",
    "    \"GPT-4o\": tiktoken.get_encoding(\"o200k_base\"), \n",
    "}\n",
    "\n",
    "text = \"Learning never stops | ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ï‡§≠‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ | Â≠¶„Å≥„ÅØÊ≠¢„Åæ„Çâ„Å™„ÅÑ üòä\"\n",
    "\n",
    "print(\"Input Text:\")\n",
    "print(text)\n",
    "print()\n",
    "\n",
    "summary = []\n",
    "decoded_tokens = {}\n",
    "max_len = 0\n",
    "\n",
    "# Encode once per tokenizer:\n",
    "for model, enc in encodings.items():\n",
    "    token_ids = enc.encode(text)\n",
    "    pieces = [repr(enc.decode([tid])) for tid in token_ids]\n",
    "    # repr(...) so that leading spaces, invisible characters, and special symbols are clearly visible in the output.\n",
    "\n",
    "\n",
    "    summary.append({\n",
    "        \"Model\": model,\n",
    "        \"Vocab size\": enc.n_vocab,\n",
    "        \"Token count\": len(token_ids),\n",
    "        \"Round-trip OK\": enc.decode(token_ids) == text\n",
    "    })\n",
    "\n",
    "    # The round-trip check verifies that decoding the full token sequence reconstructs the original text exactly, confirming that tokenization is reversible for this input.\n",
    "    # Note that this round-trip correctness confirms that differences observed later are purely about segmentation, not loss of information.\n",
    "\n",
    "    decoded_tokens[model] = pieces\n",
    "    max_len = max(max_len, len(pieces))\n",
    "\n",
    "# Print Compact Summary\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"Summary:\")\n",
    "display(summary_df)\n",
    "# Build aligned token table (token index as rows)\n",
    "rows = []\n",
    "for i in range(max_len):\n",
    "    row = {\"Idx\": i}\n",
    "    for model in decoded_tokens:\n",
    "        row[model] = decoded_tokens[model][i] \\\n",
    "                        if i < len(decoded_tokens[model]) else \"\"\n",
    "        rows.append(row)\n",
    "\n",
    "tokens_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Token piece comparison:\")\n",
    "display(tokens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763852e",
   "metadata": {},
   "source": [
    " #### Analysis\n",
    " \n",
    " - GPT-2 and GPT-3 have almost identical vocabulary sizes (~50k) and produce the same token count (51 tokens) for our input sentence. Whereas GPT-4 has a much larger vocabulary (~100k) and already reduces the token count significantly to 38 tokens, indicating better coverage of non-Latin scripts and more compact subword units.\n",
    "\n",
    "- GPT-4o has the largest vocabulary (~200k) and produces only 20 tokens for the same sentence, showing a dramatic improvement in token efficiency, especially for multilingual text.\n",
    "\n",
    "- The key takeaway from this table is that newer tokenizers don‚Äôt just add vocabulary, they materially reduce token counts, which directly affects context usage, latency, and cost.\n",
    "\n",
    "- The repeated ÔøΩ (replacement character) visible in GPT-2, GPT-3 and GPT-4 columns around the Hindi/Japanese and emoji segments indicates that these tokenizers are effectively operating at a fragmented Unicode level for those scripts.\n",
    "\n",
    "- This fragmentation happens because these tokenizers were trained with weaker coverage for non-Latin scripts, so they fall back to representing tokens as smaller, less meaningful units.\n",
    "\n",
    "- In the table, we are decoding one token at a time, which means each token is decoded in isolation, without its neighboring bytes. Many Unicode characters (such as Hindi letters, Japanese characters, and emojis) are represented by multiple bytes (due to weaker coverage for non-Latin scripts), and decoding only a fragment of those bytes produces invalid Unicode, which when decoded on their own, are shown as ÔøΩ. This is why the full round-trip decode works correctly, but several individual token pieces are unable to render when shown separately.\n",
    "\n",
    "- You can also observe that GPT-4o groups larger semantic chunks together, which is why it needs far fewer rows (tokens) overall.\n",
    "\n",
    "- Leading spaces and separators appear attached to tokens in several places, which is expected behavior and reflects how tokenizers optimize for natural language statistics rather than word boundaries.\n",
    "\n",
    "- Now, the most important practical insight from this output is that tokenization quality strongly affects multilingual robustness and efficiency, even before embeddings, attention, or model architecture come into play.\n",
    "\n",
    "- This is why prompt length, context limits, and cost estimates must always be understood relative to the tokenizer used by the target model, not by counting characters or words. Hence, the token count is practically a very important metric for performance evaluations and cost management.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414f606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
