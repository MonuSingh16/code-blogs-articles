{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer\n",
    "\n",
    "CountVectorizer is a tool commonly used in natural language processing (NLP) to convert a collection of text documents into a matrix of token counts. It's part of the scikit-learn library in Python. You can use CountVectorizer to tokenize names and create a matrix representing the frequency of each token in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (Tokens): ['alice' 'bob' 'brown' 'doe' 'jane' 'john' 'johnson' 'smith']\n",
      "Token Count Matrix:\n",
      "[[0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 1]\n",
      " [0 1 0 0 0 0 1 0]\n",
      " [1 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Samples names\n",
    "names = [\"John Doe\", \"Jane Smith\", \"Bob Johnson\", \"Alice Brown\"]\n",
    "\n",
    "# Create an instance of Count Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the names to obtain the token count matrix\n",
    "X = vectorizer.fit_transform(names)\n",
    "\n",
    "# Get the feature names (tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the matrix to an array for easier inspection\n",
    "matrix_array = X.toarray()\n",
    "\n",
    "# Display the feature names and token count matrix\n",
    "print(\"Feature Names (Tokens):\", feature_names)\n",
    "print(\"Token Count Matrix:\")\n",
    "print(matrix_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (Tokens): ['alice' 'alice brown' 'bob' 'bob johnson' 'brown' 'doe' 'jane'\n",
      " 'jane smith' 'john' 'john doe' 'johnson' 'smith']\n",
      "Token Count Matrix:\n",
      "[[0 0 0 0 0 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 0 0 0 1 0]\n",
      " [1 1 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "names = [\"John Doe\", \"Jane Smith\", \"Bob Johnson\", \"Alice Brown\"]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), lowercase=True)\n",
    "X = vectorizer.fit_transform(names)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "matrix_array = X.toarray()\n",
    "\n",
    "# Display the feature names and token count matrix\n",
    "print(\"Feature Names (Tokens):\", feature_names)\n",
    "print(\"Token Count Matrix:\")\n",
    "print(matrix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Differentiate between fit() and transform() method ? Can we apply transform() method to test data ?\n",
    "\n",
    "In summary, fit() is used to learn parameters or statistics from the training data, and transform() applies these learned parameters to new data. If a transformer has both methods, using fit_transform() can be more efficient than calling fit() and transform() separately.\n",
    "\n",
    "Yes, absolutely! In scikit-learn and many other machine learning frameworks, after you've trained a transformer using the fit() method on your training data, you can use the transform() method to apply the same transformations to new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform new data using the previously fitted vectorizer\n",
    "new_data = [\"This is a new document.\"]\n",
    "transformed_data = vectorizer.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Data:\n",
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]]\n",
      "Transformed Test Data:\n",
      "[[1 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_data = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "test_data = [\"This is a new document.\"]\n",
    "\n",
    "# Create a instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_data)\n",
    "\n",
    "# Transform both training and test data\n",
    "train_transformed = vectorizer.transform(train_data)\n",
    "test_transformed = vectorizer.transform(test_data)\n",
    "\n",
    "# The transformed data is ready to be used in ML\n",
    "print(\"Transformed Training Data:\")\n",
    "print(train_transformed.toarray())\n",
    "\n",
    "print(\"Transformed Test Data:\")\n",
    "print(test_transformed.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
