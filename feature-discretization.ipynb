{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Discretization (Binning)\n",
    "\n",
    "Discretization, also known as binning, is the process of converting continuous numerical variables into discrete intervals or bins. This can be useful in various machine learning scenarios, especially when working with models that benefit from categorical input features or when dealing with non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  True_Label  Prediction\n",
      "9    70           1           0\n",
      "11   80           1           0\n",
      "0    25           0           0\n",
      "Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a larger sample dataset\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95],\n",
    "    'Outcome': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['Age']]\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier with a single tree\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display predictions and true labels\n",
    "result_df = pd.DataFrame({'Age': X_test['Age'], 'True_Label': y_test, 'Prediction': y_pred})\n",
    "print(result_df)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monusingh/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95],\n",
    "    'Outcome': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['Age']]\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Discretize the 'Age' feature into three bins using equal-width binning\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "X_train_binned = discretizer.fit_transform(X_train)\n",
    "X_test_binned = discretizer.transform(X_test)\n",
    "\n",
    "# Train a decision tree classifier on the binned training set\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_binned, y_train)\n",
    "\n",
    "# Make predictions on the binned testing set\n",
    "y_pred = model.predict(X_test_binned)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "- We have a continuous numerical feature 'Age' and a binary target variable 'Outcome.'\n",
    "- We split the dataset into training and testing sets.\n",
    "- We use KBinsDiscretizer from scikit-learn to discretize the 'Age' feature into three bins using equal-width binning (other strategies include 'quantile' and 'kmeans').\n",
    "- We train a decision tree classifier on the binned training set and evaluate its performance on the binned testing set.\n",
    "\n",
    "> Note that the `encode='ordinal'` argument specifies that the bins should be represented as integers. Other encoding options include `'onehot'` and `'onehot-dense,'` which represent bins using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
