{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting\n",
    "\n",
    "AdaBoost is one of the first and most popular boosting algorithms. It assigns weights to training instances and adjusts them at each iteration to focus on the misclassified examples.\n",
    "\n",
    "**Working of AdaBoost:**\n",
    "\n",
    "1. Initialize Weights: Assign equal weights to all training examples.\n",
    "\n",
    "2. Train Weak Learner: Train a weak learner (e.g., a shallow decision tree) on the training data. Evaluate the performance of the weak learner on the training set.\n",
    "\n",
    "3. Compute Error: Compute the weighted error rate of the weak learner, giving more weight to misclassified examples.The error rate is calculated as the sum of weights of misclassified examples divided by the total weights.\n",
    "\n",
    "4. Compute Weight for Weak Learner: Calculate the weight of the weak learner in the final prediction based on its error rate. A smaller error rate gives a higher weight to the weak learner.\n",
    "\n",
    "5. Update Weights: Update the weights of the training examples, increasing the weights of misclassified examples.This focuses the next weak learner on the previously misclassified examples.\n",
    "\n",
    "6. Repeat: Repeat steps 2-5 for a predefined number of iterations or until a perfect model is achieved.\n",
    "\n",
    "7. Combine Weak Learners:Combine the weak learners into a strong learner by assigning weights to their predictions based on their computed weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an AdaBoost classifier with decision tree as base learner\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a change "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
