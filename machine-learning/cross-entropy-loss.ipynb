{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Entropy Loss :\n",
    "\n",
    "Cross-entropy, often referred to as log loss, is a measure used in classification problems to quantify the difference between predicted probabilities and actual class labels. It is commonly used in scenarios where the model outputs probability distributions over multiple classes. The formula for binary classification is:\n",
    "\n",
    "$Cross-Entropy Loss = -(y.log(p)) + (1-y).log(1-p)$\n",
    "\n",
    "For multiclass classification, the formula is generalized to:\n",
    "\n",
    "$Cross-Entropy Loss = -\\sum\\limits_{i=1}^{C} y_i . log(p_i)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss (TensorFlow): 0.2231\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example Data\n",
    "true_label = tf.constant([1.0])\n",
    "predicted_prob = tf.constant([0.8])\n",
    "\n",
    "# Binary Cross-Entropy Loss\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()(true_label, predicted_prob)\n",
    "print(f\"Binary Cross-Entropy Loss (TensorFlow): {bce_loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Cross-Entropy Loss (TensorFlow): 0.3567\n"
     ]
    }
   ],
   "source": [
    "# Example Data (Multiclass)\n",
    "true_labels_multiclass = tf.constant([1, 0, 0])  # One-hot encoded or integer labels\n",
    "predicted_probs_multiclass = tf.constant([0.7, 0.2, 0.1])\n",
    "\n",
    "# Categorical Cross-Entropy Loss\n",
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()(true_labels_multiclass, predicted_probs_multiclass)\n",
    "print(f\"Categorical Cross-Entropy Loss (TensorFlow): {cce_loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss (PyTorch): 0.2231\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example Data\n",
    "true_label_torch = torch.tensor([1.0])\n",
    "predicted_prob_torch = torch.tensor([0.8])\n",
    "\n",
    "bce_loss_torch = nn.BCELoss()(predicted_prob_torch, true_label_torch)\n",
    "print(f\"Binary Cross-Entropy Loss (PyTorch): {bce_loss_torch.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss (PyTorch): 0.4158\n"
     ]
    }
   ],
   "source": [
    "# Example Data (Multiclass)\n",
    "true_labels_multiclass_torch = torch.tensor([0])  # Integer labels\n",
    "predicted_logits_multiclass_torch = torch.tensor([[1.2, -0.5, 0.1]])\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "ce_loss_torch = nn.CrossEntropyLoss()(predicted_logits_multiclass_torch, true_labels_multiclass_torch)\n",
    "print(f\"Cross-Entropy Loss (PyTorch): {ce_loss_torch.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
