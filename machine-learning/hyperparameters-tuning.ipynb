{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamter tuning\n",
    "\n",
    "Hyperparameter tuning involves finding the optimal set of hyperparameters for a machine learning model to improve its performance. Hyperparameters are external configurations that are not learned from the data but are set before the training process. Techniques for hyperparameter tuning include grid search, random search, and more advanced methods like Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'gamma': 1}\n",
      "Accuracy on Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creata an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Create a grid search object with Cross Validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hypeparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on testing set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy on Testing Set:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Grid search exhaustively searches through all possible combinations of hyperparameters, which may become computationally expensive for larger search spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Random Search): {'C': 732.0939418114051, 'gamma': 5.996584841970366}\n",
      "Accuracy on Testing Set (Random Search): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define a random hyperparameter search space\n",
    "param_dist = {'C': uniform(0.1, 1000), 'gamma': uniform(0.01, 10)}\n",
    "\n",
    "# Create a random search object with cross-validation\n",
    "random_search = RandomizedSearchCV(svm, param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params_random = random_search.best_params_\n",
    "best_model_random = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the testing set\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "\n",
    "print(\"Best Hyperparameters (Random Search):\", best_params_random)\n",
    "print(\"Accuracy on Testing Set (Random Search):\", accuracy_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this random search example, uniform distributions are used to sample hyperparameters randomly within specified ranges. The n_iter parameter controls the number of random combinations to try. Random search is particularly useful when the hyperparameter search space is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
