{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF \n",
    "\n",
    "It is a numerical statistic used in information retrieval and text mining to evaluate the importance of a word in a document relative to a collection of documents (corpus). The TF-IDF value increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. This helps to highlight terms that are unique to a particular document and are not common across the entire corpus.\n",
    "\n",
    "$TF-IDF(t,d,D) = TF(t,d) * IDF(t, D)$\n",
    "\n",
    "Where :\n",
    "\n",
    "$TF(t,d)$ is the Term Frequency, representing how often term $t$ appears in document $d$.\n",
    "$IDF(t,D)$ is the Inverse Document Frequency, calculated as $log(N/n_t)$\n",
    "- $N$ is the total number of documents in the corpus and \n",
    "- $n_t$ is the number of documents containing term $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer:\n",
    "\n",
    "In scikit-learn, the TfidfVectorizer is a transformer that helps convert a collection of raw documents to a matrix of TF-IDF features. It combines the functionalities of `CountVectorizer` and `TfidfTransformer`. Here's a brief explanation of the key parameters:\n",
    "\n",
    "1. `sublinear_tf` (default=False): If True, apply sublinear scaling to the TF (Term Frequency),i.e., replace TF with $1+log(TF)$\n",
    "2. `smooth_idf` (default=True): Add 1 to document frequencies to prevent zero divisions.\n",
    "3. `use_idf` (default=True): Enable the IDF (Inverse Document Frequency) reweighting.\n",
    "4. `ngram_range` (default=(1, 1)): The range of n-grams to extract, e.g., `(1, 1)` for unigrams, `(1, 2)` for unigrams and bigrams\n",
    "5. `max_df` (default=1.0): Ignore terms with a document frequency higher than the given threshold.\n",
    "6. `min_df` (default=1): Ignore terms with a document frequency lower than the given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.4090901  0.57496187 0.4090901  0.         0.4090901  0.4090901 ]\n",
      " [0.66758217 0.         0.33379109 0.46913173 0.33379109 0.33379109]]\n",
      "\n",
      "Feature Names(tokens): ['document' 'first' 'is' 'second' 'the' 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# The resulting matrix is a spares matrix of TF-IDF features\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"\\nFeature Names(tokens):\", feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
