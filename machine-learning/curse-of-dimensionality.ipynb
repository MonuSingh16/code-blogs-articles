{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curse of dimensionality\n",
    "\n",
    "1. Increased data reuqirement\n",
    "2. Sparsity of Data\n",
    "3. Overfitting\n",
    "4. Computational Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 20 features: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a synthetic dataset with 100 samples and 20 features\n",
    "X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with 20 features: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 200 features: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Increase the dimensionality to 200 features\n",
    "X_high_dimensional, _ = make_classification(n_samples=100, n_features=200, random_state=42)\n",
    "X_train_high_dim, X_test_high_dim = train_test_split(X_high_dimensional, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the same classifier on the high-dimensional data\n",
    "clf_high_dim = RandomForestClassifier(random_state=42)\n",
    "clf_high_dim.fit(X_train_high_dim, y_train)\n",
    "\n",
    "# Evaluate the model on the high-dimensional test set\n",
    "y_pred_high_dim = clf_high_dim.predict(X_test_high_dim)\n",
    "accuracy_high_dim = accuracy_score(y_test, y_pred_high_dim)\n",
    "print(f\"Accuracy with 200 features: {accuracy_high_dim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we observe that as the dimensionality increases, the performance of the classifier may decrease due to the curse of dimensionality. This underscores the importance of feature selection or dimensionality reduction techniques to mitigate these challenges in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
