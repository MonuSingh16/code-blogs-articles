{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68b5ef4",
   "metadata": {},
   "source": [
    "#### LoRA\n",
    "\n",
    "LoRA, or Low-Rank Adaptation, is a technique designed for fine-tuning large models efficiently by only updating a small set of additional parameters. Instead of modifying all parameters of a pretrained model, LoRA keeps the original weights frozen and introduces two low-rank matrices that approximate the necessary changes during training.\n",
    "\n",
    "```py\n",
    "W_new = W_original + ΔW\n",
    "ΔW = A × B\n",
    "```\n",
    "\n",
    "- W_original: Frozen pre-trained weights\n",
    "- A: Matrix of size (d × r)\n",
    "- B: Matrix of size (r × k)\n",
    "- r: Rank (much smaller than d and k)\n",
    "\n",
    "```py\n",
    "Original: h = W × x\n",
    "LoRA: h = W × x + (B × A) × x\n",
    "```\n",
    "\n",
    "This low-rank decomposition allows the model to adapt to new tasks with significantly fewer trainable parameters, reducing both memory usage and computational overhead during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2e46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Load a small model (adjust the model name as needed)\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15345e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tokenizer chat template if needed\n",
    "if not tokenizer.chat_template:\n",
    "    tokenizer.chat_template = \"\"\"{% for message in messages %}\n",
    "            {% if message['role'] == 'system' %}System: {{ message['content'] }}\\n\n",
    "            {% elif message['role'] == 'user' %}User: {{ message['content'] }}\\n\n",
    "            {% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }} <|endoftext|>\n",
    "            {% endif %}\n",
    "            {% endfor %}\"\"\"\n",
    "\n",
    "if not tokenizer.pad_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-blogs-articles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
