{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# torch.manual_seed(1337) ensures our training results can be repeated. \n",
    "# That’s important when debugging or running comparisons, randomness in\n",
    "# weight initialization and batching can otherwise make runs inconsistent.\n",
    "torch.manual_seed(3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64 # Dimension of the hidden state\n",
    "transformer_layers = 6 # Number of transformer layers\n",
    "num_heads = 2 # Multi-head attention heads, lets model learn different representations of the input data\n",
    "block_size = 32 # No of inputs blocks model can see at once\n",
    "rms_norm_eps = 1e-5 # Epsilon value for RMS normalization\n",
    "rope_theta = 10000.0\n",
    "\n",
    "num_experts = 8 # Number of experts in the mixture of experts model per layer\n",
    "select_experts_per_token = 2 # Top-K gating, for every token, router picks two experts\n",
    "expert_output_dim = hidden_dim * 2 # Each expert MLP expands the token’s dimensionality to a wider hidden space before projecting it back down. \n",
    "shared_expert_output_dim = hidden_dim * 2 #  If we ever use shared FFNs, this would be their size. \n",
    "\n",
    "learning_rate = 5e-4\n",
    "batch_size = 32 # We process 32 sequences at a time during training.\n",
    "epochs = 1000\n",
    "eval_interval = 200\n",
    "\n",
    "assert hidden_dim % num_heads == 0, \"hidden dim is not divisible by num heads\"\n",
    "dim_k = hidden_dim // num_heads\n",
    "# Each attention head works on a chunk of the embedding, and this derived value defines how big that chunk is. For us: 128 / 4 = 32 per head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 347 characters.\n"
     ]
    }
   ],
   "source": [
    "input_data = (\"Facebook was founded in a dorm room \"\n",
    "              \"at Harvard by Mark Zuckerberg and \" \n",
    "              \"his roommates. What began as a small \"\n",
    "              \"social experiment soon transformed \"\n",
    "              \"into a global platform, connecting \"\n",
    "              \"billions of people across the world. \"\n",
    "              \"Over the years, it expanded beyond \"\n",
    "              \"profiles and friend requests, \"\n",
    "              \"introducing features like the News \"\n",
    "              \"Feed, Messenger, and Marketplace.\")\n",
    "# This is our training data, which is the raw material our model will learn patterns from.\n",
    "total_chars = len(input_data)\n",
    "\n",
    "print(f\"Training data has {total_chars} characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0,\n",
      " ',': 1,\n",
      " '.': 2,\n",
      " 'F': 3,\n",
      " 'H': 4,\n",
      " 'M': 5,\n",
      " 'N': 6,\n",
      " 'O': 7,\n",
      " 'W': 8,\n",
      " 'Z': 9,\n",
      " 'a': 10,\n",
      " 'b': 11,\n",
      " 'c': 12,\n",
      " 'd': 13,\n",
      " 'e': 14,\n",
      " 'f': 15,\n",
      " 'g': 16,\n",
      " 'h': 17,\n",
      " 'i': 18,\n",
      " 'k': 19,\n",
      " 'l': 20,\n",
      " 'm': 21,\n",
      " 'n': 22,\n",
      " 'o': 23,\n",
      " 'p': 24,\n",
      " 'q': 25,\n",
      " 'r': 26,\n",
      " 's': 27,\n",
      " 't': 28,\n",
      " 'u': 29,\n",
      " 'v': 30,\n",
      " 'w': 31,\n",
      " 'x': 32,\n",
      " 'y': 33}\n",
      "{0: ' ',\n",
      " 1: ',',\n",
      " 2: '.',\n",
      " 3: 'F',\n",
      " 4: 'H',\n",
      " 5: 'M',\n",
      " 6: 'N',\n",
      " 7: 'O',\n",
      " 8: 'W',\n",
      " 9: 'Z',\n",
      " 10: 'a',\n",
      " 11: 'b',\n",
      " 12: 'c',\n",
      " 13: 'd',\n",
      " 14: 'e',\n",
      " 15: 'f',\n",
      " 16: 'g',\n",
      " 17: 'h',\n",
      " 18: 'i',\n",
      " 19: 'k',\n",
      " 20: 'l',\n",
      " 21: 'm',\n",
      " 22: 'n',\n",
      " 23: 'o',\n",
      " 24: 'p',\n",
      " 25: 'q',\n",
      " 26: 'r',\n",
      " 27: 's',\n",
      " 28: 't',\n",
      " 29: 'u',\n",
      " 30: 'v',\n",
      " 31: 'w',\n",
      " 32: 'x',\n",
      " 33: 'y'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(input_data))) # all unique characters\n",
    "# set() removes duplicates, sorted() sorts the characters\n",
    "# This gives us a list of unique characters in the input data.\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# We create a mapping from characters to integers and vice versa.\n",
    "char_to_int = {i:idx for idx,i in enumerate(chars)}\n",
    "\n",
    "# This is a dictionary that maps each character to a unique integer.\n",
    "int_to_char = {idx:i for idx,i in enumerate(chars)}\n",
    "\n",
    "pprint(char_to_int), pprint(int_to_char)\n",
    "\n",
    "# Corresponding charaecters to integers mapping in the input data\n",
    "# This is a list comprehension that iterates over each character in the input data\n",
    "encoded_input_data = [char_to_int[ch] for ch in input_data]\n",
    "\n",
    "# Convert the encoded input data to a PyTorch tensor\n",
    "input_data_tensor = torch.tensor(encoded_input_data, dtype=torch.long, device=device)\n",
    "\n",
    "len(input_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data (input-target pairs)\n",
    "# Given a sequence of tokens, the model tries to predict the very next one.\n",
    "# In every training example, we give it a chunk of tokens (x) and ask it to predict the next chunk (y),\n",
    "# which is just x shifted one position forward.\n",
    "input_x = []\n",
    "output_y = []\n",
    "\n",
    "for i in range(len(input_data_tensor) - block_size):\n",
    "    \n",
    "    x = input_data_tensor[i : i + block_size]\n",
    "    y = input_data_tensor[i + 1 : i + block_size + 1]\n",
    "    \n",
    "    input_x.append(x)\n",
    "    output_y.append(y)\n",
    "\n",
    "# torch.stack these lists to create two large tensors, one for all inputs and one for all targets.\n",
    "train_x = torch.stack(input_x)\n",
    "train_y = torch.stack(output_y)\n",
    "\n",
    "print(input_x[0]), print(output_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(34, 64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maps each vocab_size unique tokens to a hidden_dim sized vector\n",
    "# When we pass in a batch of token sequences (shape: B x T), \n",
    "# the output is a batch of embeddings (shape: B x T x d_model). \n",
    "character_embedding_map = nn.Embedding(vocab_size, hidden_dim).to(device)\n",
    "character_embedding_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates 1D positional encodings for each token in the input sequence.\n",
    "# Generates numbers starting from 0 up to dim_k, with a step of 2.\n",
    "\n",
    "# RoPE encodes position by rotating pairs of features inside query (Q) \n",
    "# and key (K) vectors. Instead of tacking on a separate position vector, \n",
    "# it twists the data inside Q and K using position-dependent angles.\n",
    "rope_range = torch.arange(0, dim_k, 2, dtype=torch.float, device=device)\n",
    "rope_freqs = 1.0 / (rope_theta ** (rope_range / dim_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_before_attn = []\n",
    "rms_after_attn = []\n",
    "\n",
    "for i in range(transformer_layers):\n",
    "\n",
    "    weight_before_attn = nn.Parameter(torch.ones(hidden_dim, device=device))\n",
    "    rms_before_attn.append(weight_before_attn)\n",
    "\n",
    "    weight_after_attn = nn.Parameter(torch.ones(hidden_dim, device=device))\n",
    "    rms_after_attn.append(weight_after_attn)\n",
    "    \n",
    "rms_before_final_output = nn.Parameter(torch.ones(hidden_dim, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multi_head_layers = []\n",
    "feed_forward_layers = []\n",
    "\n",
    "for i in range(transformer_layers):\n",
    "\n",
    "    qkv_layer = nn.Linear(hidden_dim, 3 * hidden_dim, bias=False).to(device)\n",
    "    multi_head_layers.append(qkv_layer)\n",
    "\n",
    "    feed_forw_layer = nn.Linear(hidden_dim, hidden_dim, bias=False).to(device)\n",
    "    feed_forward_layers.append(feed_forw_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_layer = [] \n",
    "expert_feedforward_first_layer = []\n",
    "expert_feedforward_second_layer = []  \n",
    "\n",
    "shared_expert_layer = []\n",
    "shared_expert_feedforward_first_layer = []\n",
    "shared_expert_feedforward_second_layer = [] \n",
    "\n",
    "\n",
    "for i in range(transformer_layers):\n",
    "    router_linear_layer = nn.Linear(hidden_dim, num_experts, bias=False).to(device)\n",
    "    router_layer.append(router_linear_layer)\n",
    "\n",
    "\n",
    "    expert_first_layer = nn.Parameter(torch.empty(num_experts, hidden_dim, 2 * expert_output_dim, device=device))\n",
    "    nn.init.normal_(expert_first_layer, mean=0.0, std=0.05)\n",
    "    expert_feedforward_first_layer.append(expert_first_layer)\n",
    "\n",
    "    expert_second_layer = nn.Parameter(torch.empty(num_experts, expert_output_dim, hidden_dim, device=device))\n",
    "    nn.init.normal_(expert_second_layer, mean=0.0, std=0.05)\n",
    "    expert_feedforward_second_layer.append(expert_second_layer)\n",
    "\n",
    "    shared_gate = nn.Linear(hidden_dim, shared_expert_output_dim, bias=False).to(device)\n",
    "    shared_feedforward_first_layer = nn.Linear(hidden_dim, shared_expert_output_dim, bias=False).to(device)\n",
    "    shared_feedforward_second_layer = nn.Linear(shared_expert_output_dim, hidden_dim, bias=False).to(device)\n",
    "    \n",
    "    shared_expert_layer.append(shared_gate)\n",
    "    shared_expert_feedforward_first_layer.append(shared_feedforward_first_layer)\n",
    "    shared_expert_feedforward_second_layer.append(shared_feedforward_second_layer)\n",
    "\n",
    "activation_fn = nn.SiLU()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_modeling_head = nn.Linear(hidden_dim, vocab_size, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_mask = torch.tril(torch.ones(block_size, block_size, device=device))\n",
    "lm_mask = lm_mask.view(1, 1, block_size, block_size)\n",
    "\n",
    "lm_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2,176\n"
     ]
    }
   ],
   "source": [
    "trainable_parameters = list(character_embedding_map.parameters())\n",
    "\n",
    "total_params = sum(p.numel() for p in trainable_parameters if p.requires_grad)\n",
    "\n",
    "print(f\"Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 3,008\n"
     ]
    }
   ],
   "source": [
    "trainable_parameters.extend(rms_before_attn)\n",
    "trainable_parameters.extend(rms_after_attn)\n",
    "trainable_parameters.append(rms_before_final_output)\n",
    "\n",
    "total_params = sum(p.numel() for p in trainable_parameters if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 101,312\n"
     ]
    }
   ],
   "source": [
    "for i in range(transformer_layers):\n",
    "    trainable_parameters.extend(list(multi_head_layers[i].parameters()))\n",
    "    trainable_parameters.extend(list(feed_forward_layers[i].parameters()))\n",
    "\n",
    "total_params = sum(p.numel() for p in trainable_parameters if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1,431,488\n"
     ]
    }
   ],
   "source": [
    "for i in range(transformer_layers):\n",
    "    trainable_parameters.extend(list(router_layer[i].parameters()))\n",
    "\n",
    "trainable_parameters.extend(expert_feedforward_first_layer)\n",
    "trainable_parameters.extend(expert_feedforward_second_layer)\n",
    "\n",
    "for i in range(transformer_layers):\n",
    "    trainable_parameters.extend(list(shared_expert_layer[i].parameters()))\n",
    "    trainable_parameters.extend(list(shared_expert_feedforward_first_layer[i].parameters()))\n",
    "    trainable_parameters.extend(list(shared_expert_feedforward_second_layer[i].parameters()))\n",
    "\n",
    "total_params = sum(p.numel() for p in trainable_parameters if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1,433,664\n"
     ]
    }
   ],
   "source": [
    "trainable_parameters.extend(list(language_modeling_head.parameters()))\n",
    "\n",
    "total_params = sum(p.numel() for p in trainable_parameters if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(trainable_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/1000, Loss: 3.6383\n",
      "  Epoch 3/1000, Loss: 3.3065\n",
      "  Epoch 5/1000, Loss: 3.1278\n",
      "  Epoch 7/1000, Loss: 2.9057\n",
      "  Epoch 9/1000, Loss: 2.8185\n",
      "  Epoch 11/1000, Loss: 2.7295\n",
      "  Epoch 13/1000, Loss: 2.6444\n",
      "  Epoch 15/1000, Loss: 2.5715\n",
      "  Epoch 17/1000, Loss: 2.5353\n",
      "  Epoch 19/1000, Loss: 2.4447\n",
      "  Epoch 21/1000, Loss: 2.4475\n",
      "  Epoch 23/1000, Loss: 2.3408\n",
      "  Epoch 25/1000, Loss: 2.3320\n",
      "  Epoch 27/1000, Loss: 2.2290\n",
      "  Epoch 29/1000, Loss: 2.2029\n",
      "  Epoch 31/1000, Loss: 2.2165\n",
      "  Epoch 33/1000, Loss: 2.1590\n",
      "  Epoch 35/1000, Loss: 2.1517\n",
      "  Epoch 37/1000, Loss: 2.0855\n",
      "  Epoch 39/1000, Loss: 2.0359\n",
      "  Epoch 41/1000, Loss: 2.0437\n",
      "  Epoch 43/1000, Loss: 2.0016\n",
      "  Epoch 45/1000, Loss: 1.9617\n",
      "  Epoch 47/1000, Loss: 1.8849\n",
      "  Epoch 49/1000, Loss: 1.7855\n",
      "  Epoch 51/1000, Loss: 1.7555\n",
      "  Epoch 53/1000, Loss: 1.6718\n",
      "  Epoch 55/1000, Loss: 1.5940\n",
      "  Epoch 57/1000, Loss: 1.4956\n",
      "  Epoch 59/1000, Loss: 1.4632\n",
      "  Epoch 61/1000, Loss: 1.3635\n",
      "  Epoch 63/1000, Loss: 1.3270\n",
      "  Epoch 65/1000, Loss: 1.2311\n",
      "  Epoch 67/1000, Loss: 1.0923\n",
      "  Epoch 69/1000, Loss: 1.0678\n",
      "  Epoch 71/1000, Loss: 0.9016\n",
      "  Epoch 73/1000, Loss: 0.9279\n",
      "  Epoch 75/1000, Loss: 0.8683\n",
      "  Epoch 77/1000, Loss: 0.7573\n",
      "  Epoch 79/1000, Loss: 0.7650\n",
      "  Epoch 81/1000, Loss: 0.6125\n",
      "  Epoch 83/1000, Loss: 0.6062\n",
      "  Epoch 85/1000, Loss: 0.6178\n",
      "  Epoch 87/1000, Loss: 0.5755\n",
      "  Epoch 89/1000, Loss: 0.5068\n",
      "  Epoch 91/1000, Loss: 0.4762\n",
      "  Epoch 93/1000, Loss: 0.4211\n",
      "  Epoch 95/1000, Loss: 0.4444\n",
      "  Epoch 97/1000, Loss: 0.3887\n",
      "  Epoch 99/1000, Loss: 0.3363\n",
      "  Epoch 101/1000, Loss: 0.3145\n",
      "  Epoch 103/1000, Loss: 0.3110\n",
      "  Epoch 105/1000, Loss: 0.3284\n",
      "  Epoch 107/1000, Loss: 0.2617\n",
      "  Epoch 109/1000, Loss: 0.2841\n",
      "  Epoch 111/1000, Loss: 0.2575\n",
      "  Epoch 113/1000, Loss: 0.2646\n",
      "  Epoch 115/1000, Loss: 0.2582\n",
      "  Epoch 117/1000, Loss: 0.2266\n",
      "  Epoch 119/1000, Loss: 0.2390\n",
      "  Epoch 121/1000, Loss: 0.2275\n",
      "  Epoch 123/1000, Loss: 0.2242\n",
      "  Epoch 125/1000, Loss: 0.1958\n",
      "  Epoch 127/1000, Loss: 0.2223\n",
      "  Epoch 129/1000, Loss: 0.2017\n",
      "  Epoch 131/1000, Loss: 0.1956\n",
      "  Epoch 133/1000, Loss: 0.1945\n",
      "  Epoch 135/1000, Loss: 0.2031\n",
      "  Epoch 137/1000, Loss: 0.2079\n",
      "  Epoch 139/1000, Loss: 0.1825\n",
      "  Epoch 141/1000, Loss: 0.1692\n",
      "  Epoch 143/1000, Loss: 0.1923\n",
      "  Epoch 145/1000, Loss: 0.1840\n",
      "  Epoch 147/1000, Loss: 0.1794\n",
      "  Epoch 149/1000, Loss: 0.1887\n",
      "  Epoch 151/1000, Loss: 0.1831\n",
      "  Epoch 153/1000, Loss: 0.1726\n",
      "  Epoch 155/1000, Loss: 0.1595\n",
      "  Epoch 157/1000, Loss: 0.1767\n",
      "  Epoch 159/1000, Loss: 0.1606\n",
      "  Epoch 161/1000, Loss: 0.1553\n",
      "  Epoch 163/1000, Loss: 0.1834\n",
      "  Epoch 165/1000, Loss: 0.1719\n",
      "  Epoch 167/1000, Loss: 0.1696\n",
      "  Epoch 169/1000, Loss: 0.1627\n",
      "  Epoch 171/1000, Loss: 0.1622\n",
      "  Epoch 173/1000, Loss: 0.1523\n",
      "  Epoch 175/1000, Loss: 0.1628\n",
      "  Epoch 177/1000, Loss: 0.1604\n",
      "  Epoch 179/1000, Loss: 0.1509\n",
      "  Epoch 181/1000, Loss: 0.1400\n",
      "  Epoch 183/1000, Loss: 0.1584\n",
      "  Epoch 185/1000, Loss: 0.1488\n",
      "  Epoch 187/1000, Loss: 0.1321\n",
      "  Epoch 189/1000, Loss: 0.1328\n",
      "  Epoch 191/1000, Loss: 0.1350\n",
      "  Epoch 193/1000, Loss: 0.1396\n",
      "  Epoch 195/1000, Loss: 0.1575\n",
      "  Epoch 197/1000, Loss: 0.1308\n",
      "  Epoch 199/1000, Loss: 0.1289\n",
      "  Epoch 201/1000, Loss: 0.1414\n",
      "  Epoch 203/1000, Loss: 0.1597\n",
      "  Epoch 205/1000, Loss: 0.1280\n",
      "  Epoch 207/1000, Loss: 0.1310\n",
      "  Epoch 209/1000, Loss: 0.1398\n",
      "  Epoch 211/1000, Loss: 0.1430\n",
      "  Epoch 213/1000, Loss: 0.1367\n",
      "  Epoch 215/1000, Loss: 0.1321\n",
      "  Epoch 217/1000, Loss: 0.1302\n",
      "  Epoch 219/1000, Loss: 0.1335\n",
      "  Epoch 221/1000, Loss: 0.1232\n",
      "  Epoch 223/1000, Loss: 0.1447\n",
      "  Epoch 225/1000, Loss: 0.1232\n",
      "  Epoch 227/1000, Loss: 0.1292\n",
      "  Epoch 229/1000, Loss: 0.1387\n",
      "  Epoch 231/1000, Loss: 0.1338\n",
      "  Epoch 233/1000, Loss: 0.1234\n",
      "  Epoch 235/1000, Loss: 0.1397\n",
      "  Epoch 237/1000, Loss: 0.1240\n",
      "  Epoch 239/1000, Loss: 0.1342\n",
      "  Epoch 241/1000, Loss: 0.1318\n",
      "  Epoch 243/1000, Loss: 0.1489\n",
      "  Epoch 245/1000, Loss: 0.1435\n",
      "  Epoch 247/1000, Loss: 0.1529\n",
      "  Epoch 249/1000, Loss: 0.1297\n",
      "  Epoch 251/1000, Loss: 0.1330\n",
      "  Epoch 253/1000, Loss: 0.1253\n",
      "  Epoch 255/1000, Loss: 0.1488\n",
      "  Epoch 257/1000, Loss: 0.1395\n",
      "  Epoch 259/1000, Loss: 0.1284\n",
      "  Epoch 261/1000, Loss: 0.1448\n",
      "  Epoch 263/1000, Loss: 0.1454\n",
      "  Epoch 265/1000, Loss: 0.1326\n",
      "  Epoch 267/1000, Loss: 0.1159\n",
      "  Epoch 269/1000, Loss: 0.1148\n",
      "  Epoch 271/1000, Loss: 0.1385\n",
      "  Epoch 273/1000, Loss: 0.1304\n",
      "  Epoch 275/1000, Loss: 0.1112\n",
      "  Epoch 277/1000, Loss: 0.1410\n",
      "  Epoch 279/1000, Loss: 0.1402\n",
      "  Epoch 281/1000, Loss: 0.1209\n",
      "  Epoch 283/1000, Loss: 0.1369\n",
      "  Epoch 285/1000, Loss: 0.1395\n",
      "  Epoch 287/1000, Loss: 0.1198\n",
      "  Epoch 289/1000, Loss: 0.1237\n",
      "  Epoch 291/1000, Loss: 0.1351\n",
      "  Epoch 293/1000, Loss: 0.1185\n",
      "  Epoch 295/1000, Loss: 0.1287\n",
      "  Epoch 297/1000, Loss: 0.1269\n",
      "  Epoch 299/1000, Loss: 0.1311\n",
      "  Epoch 301/1000, Loss: 0.1190\n",
      "  Epoch 303/1000, Loss: 0.1240\n",
      "  Epoch 305/1000, Loss: 0.1198\n",
      "  Epoch 307/1000, Loss: 0.1227\n",
      "  Epoch 309/1000, Loss: 0.1271\n",
      "  Epoch 311/1000, Loss: 0.1200\n",
      "  Epoch 313/1000, Loss: 0.1144\n",
      "  Epoch 315/1000, Loss: 0.1178\n",
      "  Epoch 317/1000, Loss: 0.1284\n",
      "  Epoch 319/1000, Loss: 0.1240\n",
      "  Epoch 321/1000, Loss: 0.1224\n",
      "  Epoch 323/1000, Loss: 0.1289\n",
      "  Epoch 325/1000, Loss: 0.1201\n",
      "  Epoch 327/1000, Loss: 0.1179\n",
      "  Epoch 329/1000, Loss: 0.1289\n",
      "  Epoch 331/1000, Loss: 0.1289\n",
      "  Epoch 333/1000, Loss: 0.1282\n",
      "  Epoch 335/1000, Loss: 0.1216\n",
      "  Epoch 337/1000, Loss: 0.1239\n",
      "  Epoch 339/1000, Loss: 0.1039\n",
      "  Epoch 341/1000, Loss: 0.1134\n",
      "  Epoch 343/1000, Loss: 0.1123\n",
      "  Epoch 345/1000, Loss: 0.1287\n",
      "  Epoch 347/1000, Loss: 0.1118\n",
      "  Epoch 349/1000, Loss: 0.1199\n",
      "  Epoch 351/1000, Loss: 0.1158\n",
      "  Epoch 353/1000, Loss: 0.1225\n",
      "  Epoch 355/1000, Loss: 0.1282\n",
      "  Epoch 357/1000, Loss: 0.1186\n",
      "  Epoch 359/1000, Loss: 0.1161\n",
      "  Epoch 361/1000, Loss: 0.1139\n",
      "  Epoch 363/1000, Loss: 0.1340\n",
      "  Epoch 365/1000, Loss: 0.1187\n",
      "  Epoch 367/1000, Loss: 0.1231\n",
      "  Epoch 369/1000, Loss: 0.1139\n",
      "  Epoch 371/1000, Loss: 0.1197\n",
      "  Epoch 373/1000, Loss: 0.1222\n",
      "  Epoch 375/1000, Loss: 0.0961\n",
      "  Epoch 377/1000, Loss: 0.1171\n",
      "  Epoch 379/1000, Loss: 0.1243\n",
      "  Epoch 381/1000, Loss: 0.1196\n",
      "  Epoch 383/1000, Loss: 0.1109\n",
      "  Epoch 385/1000, Loss: 0.1139\n",
      "  Epoch 387/1000, Loss: 0.1196\n",
      "  Epoch 389/1000, Loss: 0.1017\n",
      "  Epoch 391/1000, Loss: 0.1296\n",
      "  Epoch 393/1000, Loss: 0.0991\n",
      "  Epoch 395/1000, Loss: 0.1223\n",
      "  Epoch 397/1000, Loss: 0.1273\n",
      "  Epoch 399/1000, Loss: 0.1100\n",
      "  Epoch 401/1000, Loss: 0.1155\n",
      "  Epoch 403/1000, Loss: 0.1278\n",
      "  Epoch 405/1000, Loss: 0.1299\n",
      "  Epoch 407/1000, Loss: 0.1168\n",
      "  Epoch 409/1000, Loss: 0.0924\n",
      "  Epoch 411/1000, Loss: 0.1093\n",
      "  Epoch 413/1000, Loss: 0.0988\n",
      "  Epoch 415/1000, Loss: 0.1177\n",
      "  Epoch 417/1000, Loss: 0.1174\n",
      "  Epoch 419/1000, Loss: 0.1128\n",
      "  Epoch 421/1000, Loss: 0.1336\n",
      "  Epoch 423/1000, Loss: 0.1167\n",
      "  Epoch 425/1000, Loss: 0.1233\n",
      "  Epoch 427/1000, Loss: 0.0999\n",
      "  Epoch 429/1000, Loss: 0.1093\n",
      "  Epoch 431/1000, Loss: 0.1110\n",
      "  Epoch 433/1000, Loss: 0.1032\n",
      "  Epoch 435/1000, Loss: 0.1257\n",
      "  Epoch 437/1000, Loss: 0.1050\n",
      "  Epoch 439/1000, Loss: 0.1087\n",
      "  Epoch 441/1000, Loss: 0.1144\n",
      "  Epoch 443/1000, Loss: 0.1234\n",
      "  Epoch 445/1000, Loss: 0.1433\n",
      "  Epoch 447/1000, Loss: 0.1253\n",
      "  Epoch 449/1000, Loss: 0.1119\n",
      "  Epoch 451/1000, Loss: 0.1163\n",
      "  Epoch 453/1000, Loss: 0.1134\n",
      "  Epoch 455/1000, Loss: 0.1331\n",
      "  Epoch 457/1000, Loss: 0.1255\n",
      "  Epoch 459/1000, Loss: 0.1131\n",
      "  Epoch 461/1000, Loss: 0.1032\n",
      "  Epoch 463/1000, Loss: 0.1151\n",
      "  Epoch 465/1000, Loss: 0.1285\n",
      "  Epoch 467/1000, Loss: 0.1248\n",
      "  Epoch 469/1000, Loss: 0.1128\n",
      "  Epoch 471/1000, Loss: 0.1051\n",
      "  Epoch 473/1000, Loss: 0.1117\n",
      "  Epoch 475/1000, Loss: 0.1147\n",
      "  Epoch 477/1000, Loss: 0.1149\n",
      "  Epoch 479/1000, Loss: 0.1087\n",
      "  Epoch 481/1000, Loss: 0.1161\n",
      "  Epoch 483/1000, Loss: 0.1052\n",
      "  Epoch 485/1000, Loss: 0.1133\n",
      "  Epoch 487/1000, Loss: 0.1058\n",
      "  Epoch 489/1000, Loss: 0.1125\n",
      "  Epoch 491/1000, Loss: 0.1089\n",
      "  Epoch 493/1000, Loss: 0.1109\n",
      "  Epoch 495/1000, Loss: 0.1226\n",
      "  Epoch 497/1000, Loss: 0.1103\n",
      "  Epoch 499/1000, Loss: 0.1107\n",
      "  Epoch 501/1000, Loss: 0.1158\n",
      "  Epoch 503/1000, Loss: 0.1107\n",
      "  Epoch 505/1000, Loss: 0.1174\n",
      "  Epoch 507/1000, Loss: 0.1121\n",
      "  Epoch 509/1000, Loss: 0.1126\n",
      "  Epoch 511/1000, Loss: 0.1136\n",
      "  Epoch 513/1000, Loss: 0.1018\n",
      "  Epoch 515/1000, Loss: 0.1125\n",
      "  Epoch 517/1000, Loss: 0.1103\n",
      "  Epoch 519/1000, Loss: 0.1095\n",
      "  Epoch 521/1000, Loss: 0.1093\n",
      "  Epoch 523/1000, Loss: 0.1010\n",
      "  Epoch 525/1000, Loss: 0.1070\n",
      "  Epoch 527/1000, Loss: 0.1074\n",
      "  Epoch 529/1000, Loss: 0.1117\n",
      "  Epoch 531/1000, Loss: 0.1225\n",
      "  Epoch 533/1000, Loss: 0.1140\n",
      "  Epoch 535/1000, Loss: 0.1000\n",
      "  Epoch 537/1000, Loss: 0.1128\n",
      "  Epoch 539/1000, Loss: 0.1136\n",
      "  Epoch 541/1000, Loss: 0.1167\n",
      "  Epoch 543/1000, Loss: 0.1158\n",
      "  Epoch 545/1000, Loss: 0.1048\n",
      "  Epoch 547/1000, Loss: 0.1126\n",
      "  Epoch 549/1000, Loss: 0.1104\n",
      "  Epoch 551/1000, Loss: 0.0979\n",
      "  Epoch 553/1000, Loss: 0.0989\n",
      "  Epoch 555/1000, Loss: 0.1134\n",
      "  Epoch 557/1000, Loss: 0.1095\n",
      "  Epoch 559/1000, Loss: 0.1133\n",
      "  Epoch 561/1000, Loss: 0.1075\n",
      "  Epoch 563/1000, Loss: 0.1080\n",
      "  Epoch 565/1000, Loss: 0.1049\n",
      "  Epoch 567/1000, Loss: 0.1040\n",
      "  Epoch 569/1000, Loss: 0.1061\n",
      "  Epoch 571/1000, Loss: 0.1014\n",
      "  Epoch 573/1000, Loss: 0.1242\n",
      "  Epoch 575/1000, Loss: 0.1024\n",
      "  Epoch 577/1000, Loss: 0.1004\n",
      "  Epoch 579/1000, Loss: 0.1177\n",
      "  Epoch 581/1000, Loss: 0.1010\n",
      "  Epoch 583/1000, Loss: 0.0992\n",
      "  Epoch 585/1000, Loss: 0.1101\n",
      "  Epoch 587/1000, Loss: 0.0971\n",
      "  Epoch 589/1000, Loss: 0.1131\n",
      "  Epoch 591/1000, Loss: 0.1014\n",
      "  Epoch 593/1000, Loss: 0.1153\n",
      "  Epoch 595/1000, Loss: 0.1033\n",
      "  Epoch 597/1000, Loss: 0.0934\n",
      "  Epoch 599/1000, Loss: 0.1095\n",
      "  Epoch 601/1000, Loss: 0.0969\n",
      "  Epoch 603/1000, Loss: 0.0992\n",
      "  Epoch 605/1000, Loss: 0.0995\n",
      "  Epoch 607/1000, Loss: 0.1135\n",
      "  Epoch 609/1000, Loss: 0.1154\n",
      "  Epoch 611/1000, Loss: 0.1043\n",
      "  Epoch 613/1000, Loss: 0.1026\n",
      "  Epoch 615/1000, Loss: 0.1011\n",
      "  Epoch 617/1000, Loss: 0.1149\n",
      "  Epoch 619/1000, Loss: 0.1062\n",
      "  Epoch 621/1000, Loss: 0.1039\n",
      "  Epoch 623/1000, Loss: 0.1075\n",
      "  Epoch 625/1000, Loss: 0.0948\n",
      "  Epoch 627/1000, Loss: 0.1073\n",
      "  Epoch 629/1000, Loss: 0.1017\n",
      "  Epoch 631/1000, Loss: 0.1046\n",
      "  Epoch 633/1000, Loss: 0.0965\n",
      "  Epoch 635/1000, Loss: 0.1021\n",
      "  Epoch 637/1000, Loss: 0.1095\n",
      "  Epoch 639/1000, Loss: 0.1122\n",
      "  Epoch 641/1000, Loss: 0.1044\n",
      "  Epoch 643/1000, Loss: 0.1034\n",
      "  Epoch 645/1000, Loss: 0.1171\n",
      "  Epoch 647/1000, Loss: 0.1003\n",
      "  Epoch 649/1000, Loss: 0.1010\n",
      "  Epoch 651/1000, Loss: 0.0917\n",
      "  Epoch 653/1000, Loss: 0.1115\n",
      "  Epoch 655/1000, Loss: 0.1126\n",
      "  Epoch 657/1000, Loss: 0.0920\n",
      "  Epoch 659/1000, Loss: 0.0945\n",
      "  Epoch 661/1000, Loss: 0.0983\n",
      "  Epoch 663/1000, Loss: 0.1063\n",
      "  Epoch 665/1000, Loss: 0.0989\n",
      "  Epoch 667/1000, Loss: 0.1001\n",
      "  Epoch 669/1000, Loss: 0.1071\n",
      "  Epoch 671/1000, Loss: 0.1020\n",
      "  Epoch 673/1000, Loss: 0.1050\n",
      "  Epoch 675/1000, Loss: 0.0933\n",
      "  Epoch 677/1000, Loss: 0.1080\n",
      "  Epoch 679/1000, Loss: 0.1088\n",
      "  Epoch 681/1000, Loss: 0.1025\n",
      "  Epoch 683/1000, Loss: 0.1061\n",
      "  Epoch 685/1000, Loss: 0.1049\n",
      "  Epoch 687/1000, Loss: 0.0903\n",
      "  Epoch 689/1000, Loss: 0.0986\n",
      "  Epoch 691/1000, Loss: 0.1025\n",
      "  Epoch 693/1000, Loss: 0.1061\n",
      "  Epoch 695/1000, Loss: 0.0939\n",
      "  Epoch 697/1000, Loss: 0.1047\n",
      "  Epoch 699/1000, Loss: 0.1028\n",
      "  Epoch 701/1000, Loss: 0.1019\n",
      "  Epoch 703/1000, Loss: 0.0948\n",
      "  Epoch 705/1000, Loss: 0.1024\n",
      "  Epoch 707/1000, Loss: 0.0993\n",
      "  Epoch 709/1000, Loss: 0.0898\n",
      "  Epoch 711/1000, Loss: 0.0992\n",
      "  Epoch 713/1000, Loss: 0.1063\n",
      "  Epoch 715/1000, Loss: 0.1118\n",
      "  Epoch 717/1000, Loss: 0.1061\n",
      "  Epoch 719/1000, Loss: 0.1051\n",
      "  Epoch 721/1000, Loss: 0.1116\n",
      "  Epoch 723/1000, Loss: 0.1036\n",
      "  Epoch 725/1000, Loss: 0.1003\n",
      "  Epoch 727/1000, Loss: 0.1069\n",
      "  Epoch 729/1000, Loss: 0.0996\n",
      "  Epoch 731/1000, Loss: 0.0997\n",
      "  Epoch 733/1000, Loss: 0.1112\n",
      "  Epoch 735/1000, Loss: 0.0995\n",
      "  Epoch 737/1000, Loss: 0.1059\n",
      "  Epoch 739/1000, Loss: 0.0918\n",
      "  Epoch 741/1000, Loss: 0.1089\n",
      "  Epoch 743/1000, Loss: 0.0976\n",
      "  Epoch 745/1000, Loss: 0.0989\n",
      "  Epoch 747/1000, Loss: 0.1045\n",
      "  Epoch 749/1000, Loss: 0.1044\n",
      "  Epoch 751/1000, Loss: 0.1175\n",
      "  Epoch 753/1000, Loss: 0.1020\n",
      "  Epoch 755/1000, Loss: 0.1055\n",
      "  Epoch 757/1000, Loss: 0.0994\n",
      "  Epoch 759/1000, Loss: 0.1079\n",
      "  Epoch 761/1000, Loss: 0.1055\n",
      "  Epoch 763/1000, Loss: 0.1149\n",
      "  Epoch 765/1000, Loss: 0.1071\n",
      "  Epoch 767/1000, Loss: 0.1056\n",
      "  Epoch 769/1000, Loss: 0.0969\n",
      "  Epoch 771/1000, Loss: 0.1021\n",
      "  Epoch 773/1000, Loss: 0.1056\n",
      "  Epoch 775/1000, Loss: 0.1008\n",
      "  Epoch 777/1000, Loss: 0.1041\n",
      "  Epoch 779/1000, Loss: 0.1071\n",
      "  Epoch 781/1000, Loss: 0.1049\n",
      "  Epoch 783/1000, Loss: 0.1028\n",
      "  Epoch 785/1000, Loss: 0.0990\n",
      "  Epoch 787/1000, Loss: 0.0964\n",
      "  Epoch 789/1000, Loss: 0.1046\n",
      "  Epoch 791/1000, Loss: 0.0984\n",
      "  Epoch 793/1000, Loss: 0.1027\n",
      "  Epoch 795/1000, Loss: 0.0953\n",
      "  Epoch 797/1000, Loss: 0.1024\n",
      "  Epoch 799/1000, Loss: 0.0993\n",
      "  Epoch 801/1000, Loss: 0.1041\n",
      "  Epoch 803/1000, Loss: 0.1028\n",
      "  Epoch 805/1000, Loss: 0.1138\n",
      "  Epoch 807/1000, Loss: 0.1035\n",
      "  Epoch 809/1000, Loss: 0.1028\n",
      "  Epoch 811/1000, Loss: 0.1001\n",
      "  Epoch 813/1000, Loss: 0.1053\n",
      "  Epoch 815/1000, Loss: 0.0877\n",
      "  Epoch 817/1000, Loss: 0.1037\n",
      "  Epoch 819/1000, Loss: 0.1125\n",
      "  Epoch 821/1000, Loss: 0.0848\n",
      "  Epoch 823/1000, Loss: 0.1084\n",
      "  Epoch 825/1000, Loss: 0.0972\n",
      "  Epoch 827/1000, Loss: 0.1053\n",
      "  Epoch 829/1000, Loss: 0.0997\n",
      "  Epoch 831/1000, Loss: 0.1006\n",
      "  Epoch 833/1000, Loss: 0.0970\n",
      "  Epoch 835/1000, Loss: 0.1000\n",
      "  Epoch 837/1000, Loss: 0.1005\n",
      "  Epoch 839/1000, Loss: 0.1087\n",
      "  Epoch 841/1000, Loss: 0.1099\n",
      "  Epoch 843/1000, Loss: 0.0982\n",
      "  Epoch 845/1000, Loss: 0.0970\n",
      "  Epoch 847/1000, Loss: 0.0900\n",
      "  Epoch 849/1000, Loss: 0.0988\n",
      "  Epoch 851/1000, Loss: 0.0969\n",
      "  Epoch 853/1000, Loss: 0.1022\n",
      "  Epoch 855/1000, Loss: 0.1066\n",
      "  Epoch 857/1000, Loss: 0.0918\n",
      "  Epoch 859/1000, Loss: 0.1016\n",
      "  Epoch 861/1000, Loss: 0.0931\n",
      "  Epoch 863/1000, Loss: 0.1006\n",
      "  Epoch 865/1000, Loss: 0.1115\n",
      "  Epoch 867/1000, Loss: 0.0989\n",
      "  Epoch 869/1000, Loss: 0.0981\n",
      "  Epoch 871/1000, Loss: 0.0961\n",
      "  Epoch 873/1000, Loss: 0.1086\n",
      "  Epoch 875/1000, Loss: 0.1068\n",
      "  Epoch 877/1000, Loss: 0.0972\n",
      "  Epoch 879/1000, Loss: 0.0845\n",
      "  Epoch 881/1000, Loss: 0.1008\n",
      "  Epoch 883/1000, Loss: 0.0978\n",
      "  Epoch 885/1000, Loss: 0.0954\n",
      "  Epoch 887/1000, Loss: 0.1072\n",
      "  Epoch 889/1000, Loss: 0.0987\n",
      "  Epoch 891/1000, Loss: 0.1041\n",
      "  Epoch 893/1000, Loss: 0.1012\n",
      "  Epoch 895/1000, Loss: 0.1089\n",
      "  Epoch 897/1000, Loss: 0.1017\n",
      "  Epoch 899/1000, Loss: 0.0996\n",
      "  Epoch 901/1000, Loss: 0.0996\n",
      "  Epoch 903/1000, Loss: 0.0895\n",
      "  Epoch 905/1000, Loss: 0.1003\n",
      "  Epoch 907/1000, Loss: 0.1041\n",
      "  Epoch 909/1000, Loss: 0.0997\n",
      "  Epoch 911/1000, Loss: 0.1010\n",
      "  Epoch 913/1000, Loss: 0.0949\n",
      "  Epoch 915/1000, Loss: 0.1117\n",
      "  Epoch 917/1000, Loss: 0.0923\n",
      "  Epoch 919/1000, Loss: 0.0950\n",
      "  Epoch 921/1000, Loss: 0.0981\n",
      "  Epoch 923/1000, Loss: 0.0920\n",
      "  Epoch 925/1000, Loss: 0.1018\n",
      "  Epoch 927/1000, Loss: 0.1035\n",
      "  Epoch 929/1000, Loss: 0.0960\n",
      "  Epoch 931/1000, Loss: 0.1054\n",
      "  Epoch 933/1000, Loss: 0.1104\n",
      "  Epoch 935/1000, Loss: 0.1026\n",
      "  Epoch 937/1000, Loss: 0.0981\n",
      "  Epoch 939/1000, Loss: 0.0886\n",
      "  Epoch 941/1000, Loss: 0.0913\n",
      "  Epoch 943/1000, Loss: 0.0884\n",
      "  Epoch 945/1000, Loss: 0.0910\n",
      "  Epoch 947/1000, Loss: 0.0946\n",
      "  Epoch 949/1000, Loss: 0.0962\n",
      "  Epoch 951/1000, Loss: 0.0957\n",
      "  Epoch 953/1000, Loss: 0.0863\n",
      "  Epoch 955/1000, Loss: 0.1072\n",
      "  Epoch 957/1000, Loss: 0.0942\n",
      "  Epoch 959/1000, Loss: 0.1007\n",
      "  Epoch 961/1000, Loss: 0.0951\n",
      "  Epoch 963/1000, Loss: 0.1066\n",
      "  Epoch 965/1000, Loss: 0.1073\n",
      "  Epoch 967/1000, Loss: 0.0957\n",
      "  Epoch 969/1000, Loss: 0.0993\n",
      "  Epoch 971/1000, Loss: 0.0986\n",
      "  Epoch 973/1000, Loss: 0.1136\n",
      "  Epoch 975/1000, Loss: 0.0951\n",
      "  Epoch 977/1000, Loss: 0.1047\n",
      "  Epoch 979/1000, Loss: 0.0976\n",
      "  Epoch 981/1000, Loss: 0.1022\n",
      "  Epoch 983/1000, Loss: 0.0848\n",
      "  Epoch 985/1000, Loss: 0.1020\n",
      "  Epoch 987/1000, Loss: 0.1060\n",
      "  Epoch 989/1000, Loss: 0.1037\n",
      "  Epoch 991/1000, Loss: 0.1029\n",
      "  Epoch 993/1000, Loss: 0.0917\n",
      "  Epoch 995/1000, Loss: 0.1019\n",
      "  Epoch 997/1000, Loss: 0.0999\n",
      "  Epoch 999/1000, Loss: 0.1054\n",
      "  Epoch 1000/1000, Loss: 0.0858\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "total_samples = len(train_x)\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    batch_indices = torch.randint(0, total_samples, (batch_size,))\n",
    "    \n",
    "    input_tokens = train_x[batch_indices].to(device)\n",
    "    target_tokens = train_y[batch_indices].to(device)\n",
    "\n",
    "    bsz = input_tokens.shape[0]\n",
    "    seq_len = input_tokens.shape[1]\n",
    "    model_dim = hidden_dim\n",
    "\n",
    "    embedded_tokens = character_embedding_map(input_tokens)\n",
    "\n",
    "    pos_indices = torch.arange(seq_len, device=device).unsqueeze(0)\n",
    "\n",
    "    inv_freq_broadcasted = rope_freqs.unsqueeze(0).unsqueeze(-1).expand(bsz, -1, 1)\n",
    "    pos_ids_broadcasted = pos_indices.expand(bsz, -1).unsqueeze(1).float()\n",
    "\n",
    "    with torch.autocast(device_type=device, enabled=False):\n",
    "        angle_matrix = (inv_freq_broadcasted.float() @ pos_ids_broadcasted).transpose(1, 2)\n",
    "        freqs_complex = torch.polar(torch.ones_like(angle_matrix), angle_matrix)\n",
    "\n",
    "    layer_input = embedded_tokens\n",
    "\n",
    "    for layer_id in range(transformer_layers):\n",
    "\n",
    "        attn_residual = layer_input\n",
    "\n",
    "        x_fp32 = layer_input.float()\n",
    "        rms_norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "        normed_attn_input = (x_fp32 * rms_norm_factor).type_as(layer_input)\n",
    "        normed_attn_input = normed_attn_input * rms_before_attn[layer_id]\n",
    "\n",
    "        qkv_combined = multi_head_layers[layer_id](normed_attn_input)\n",
    "        qkv_combined = qkv_combined.view(bsz, seq_len, num_heads, 3 * dim_k)\n",
    "        queries, keys, values = qkv_combined.chunk(3, dim=-1)\n",
    "\n",
    "        queries_reshaped = queries.float().reshape(bsz, seq_len, num_heads, -1, 2)\n",
    "        keys_reshaped = keys.float().reshape(bsz, seq_len, num_heads, -1, 2)\n",
    "\n",
    "        queries_complex = torch.view_as_complex(queries_reshaped)\n",
    "        keys_complex = torch.view_as_complex(keys_reshaped)\n",
    "        freq_broadcast = freqs_complex.unsqueeze(2)\n",
    "\n",
    "        queries_rot = queries_complex * freq_broadcast\n",
    "        keys_rot = keys_complex * freq_broadcast\n",
    "\n",
    "        queries_real = torch.view_as_real(queries_rot)\n",
    "        keys_real = torch.view_as_real(keys_rot)\n",
    "\n",
    "        queries = queries_real.flatten(3).type_as(queries)\n",
    "        keys = keys_real.flatten(3).type_as(keys)\n",
    "\n",
    "        queries = queries.permute(0, 2, 1, 3)\n",
    "        keys = keys.permute(0, 2, 1, 3)\n",
    "        values = values.permute(0, 2, 1, 3)\n",
    "\n",
    "        attention_scores = (queries @ keys.transpose(-2, -1)) * (dim_k ** -0.5)\n",
    "        attention_scores = attention_scores.masked_fill(lm_mask[:, :, :seq_len, :seq_len] == 0, float('-inf'))\n",
    "\n",
    "        attn_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attn_probs = torch.nan_to_num(attn_probs)\n",
    "\n",
    "        attn_out = attn_probs @ values\n",
    "        attn_out = attn_out.permute(0, 2, 1, 3).contiguous().view(bsz, seq_len, model_dim)\n",
    "\n",
    "        attn_out = feed_forward_layers[layer_id](attn_out)\n",
    "\n",
    "        layer_input = attn_residual + attn_out\n",
    "        moe_residual = layer_input\n",
    "\n",
    "        x_fp32 = layer_input.float()\n",
    "        rms_norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "        normed_moe_input = (x_fp32 * rms_norm_factor).type_as(layer_input)\n",
    "        normed_moe_input = normed_moe_input * rms_after_attn[layer_id]\n",
    "\n",
    "        route_logits = router_layer[layer_id](normed_moe_input)\n",
    "\n",
    "        expert_scores, expert_indices = torch.topk(route_logits, select_experts_per_token, dim=-1)\n",
    "        expert_scores = torch.sigmoid(expert_scores)\n",
    "\n",
    "        flattened_input = normed_moe_input.view(-1, model_dim)\n",
    "        flattened_expert_ids = expert_indices.view(-1)\n",
    "        flattened_scores = expert_scores.view(-1)\n",
    "\n",
    "        token_positions = torch.arange(bsz * seq_len, device=device).repeat_interleave(select_experts_per_token)\n",
    "        expert_routing = flattened_expert_ids\n",
    "\n",
    "        expert_inputs = flattened_input[token_positions]\n",
    "\n",
    "        expert_up_weights = expert_feedforward_first_layer[layer_id][expert_routing]\n",
    "        expert_down_weights = expert_feedforward_second_layer[layer_id][expert_routing]\n",
    "\n",
    "        intermediate = torch.bmm(expert_inputs.unsqueeze(1), expert_up_weights)\n",
    "        gate_vals, up_vals = intermediate.chunk(2, dim=-1)\n",
    "\n",
    "        expert_activated = activation_fn(gate_vals) * up_vals\n",
    "        expert_raw_output = torch.bmm(expert_activated, expert_down_weights).squeeze(1)\n",
    "        expert_scaled_output = expert_raw_output * flattened_scores.unsqueeze(-1)\n",
    "\n",
    "        combined_outputs = torch.zeros_like(flattened_input)\n",
    "        combined_outputs.scatter_add_(0, token_positions.unsqueeze(-1).expand(-1, model_dim), expert_scaled_output)\n",
    "\n",
    "        shared_gate = shared_expert_layer[layer_id](normed_moe_input)\n",
    "        shared_up = shared_expert_feedforward_first_layer[layer_id](normed_moe_input)\n",
    "        shared_activated = activation_fn(shared_gate) * shared_up\n",
    "        shared_down = shared_expert_feedforward_second_layer[layer_id](shared_activated)\n",
    "\n",
    "        moe_out = combined_outputs.view(bsz, seq_len, model_dim)\n",
    "        moe_combined = moe_out + shared_down\n",
    "\n",
    "        layer_input = moe_residual + moe_combined\n",
    "\n",
    "    x_fp32 = layer_input.float()\n",
    "    rms_norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "    final_norm = (x_fp32 * rms_norm_factor).type_as(layer_input)\n",
    "    final_norm = final_norm * rms_before_final_output\n",
    "\n",
    "    vocab_logits = language_modeling_head(final_norm)\n",
    "\n",
    "    B, T, V = vocab_logits.shape\n",
    "    logits_flat = vocab_logits.view(B * T, V)\n",
    "    targets_flat = target_tokens.view(B * T)\n",
    "    loss = criterion(logits_flat, targets_flat)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_loss_val = loss.item()\n",
    "    epoch_losses.append(current_loss_val)\n",
    "    if ep % 2 == 0 or ep == epochs - 1:\n",
    "        print(f\"  Epoch {ep+1}/{epochs}, Loss: {current_loss_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epoch_losses)\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=34, bias=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = \"Facebook \" \n",
    "\n",
    "generation_limit = 100\n",
    "\n",
    "prompt_token_ids = [char_to_int[ch] for ch in prompt_text if ch in char_to_int]\n",
    "gen_sequence_buffer = torch.tensor([prompt_token_ids], dtype=torch.long, device=device)\n",
    "\n",
    "character_embedding_map.eval()\n",
    "for layer_idx in range(transformer_layers):\n",
    "    multi_head_layers[layer_idx].eval()\n",
    "    feed_forward_layers[layer_idx].eval()\n",
    "    router_layer[layer_idx].eval()\n",
    "    shared_expert_layer[layer_idx].eval()\n",
    "    shared_expert_feedforward_first_layer[layer_idx].eval()\n",
    "    shared_expert_feedforward_second_layer[layer_idx].eval()\n",
    "\n",
    "language_modeling_head.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(generation_limit):\n",
    "        \n",
    "        input_context = gen_sequence_buffer[:, -block_size:] \n",
    "        batch_size_gen, seq_len_gen = input_context.shape\n",
    "        hidden_size_gen = hidden_dim\n",
    "\n",
    "        embedded_input = character_embedding_map(input_context) \n",
    "\n",
    "        position_indices = torch.arange(seq_len_gen, device=device).unsqueeze(0)\n",
    "        inv_freq_broadcast = rope_freqs.unsqueeze(0).unsqueeze(-1).expand(batch_size_gen, -1, 1)\n",
    "        pos_ids_broadcast = position_indices.expand(batch_size_gen, -1).unsqueeze(1).float()\n",
    "        \n",
    "        with torch.autocast(device_type=device, enabled=False):\n",
    "            pos_angles = (inv_freq_broadcast.float() @ pos_ids_broadcast).transpose(1, 2)\n",
    "            rope_rotations = torch.polar(torch.ones_like(pos_angles), pos_angles)\n",
    "\n",
    "        layer_input = embedded_input\n",
    "\n",
    "        for layer_idx in range(transformer_layers):\n",
    "            attn_skip = layer_input\n",
    "\n",
    "            x_fp32 = layer_input.float()\n",
    "            norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "            normed_input = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "            normed_input = normed_input * rms_before_attn[layer_idx]\n",
    "\n",
    "            qkv_proj = multi_head_layers[layer_idx](normed_input)\n",
    "            qkv_proj = qkv_proj.view(batch_size_gen, seq_len_gen, num_heads, 3 * dim_k)\n",
    "            query, key, value = qkv_proj.chunk(3, dim=-1)\n",
    "\n",
    "            query_cmplx = torch.view_as_complex(query.float().reshape(batch_size_gen, seq_len_gen, num_heads, -1, 2))\n",
    "            key_cmplx = torch.view_as_complex(key.float().reshape(batch_size_gen, seq_len_gen, num_heads, -1, 2))\n",
    "            rope_cis_broadcast = rope_rotations.unsqueeze(2)\n",
    "            query_rot = query_cmplx * rope_cis_broadcast\n",
    "            key_rot = key_cmplx * rope_cis_broadcast\n",
    "            query = torch.view_as_real(query_rot).flatten(3).type_as(query)\n",
    "            key = torch.view_as_real(key_rot).flatten(3).type_as(key)\n",
    "\n",
    "            query = query.permute(0, 2, 1, 3)\n",
    "            key = key.permute(0, 2, 1, 3)\n",
    "            value = value.permute(0, 2, 1, 3)\n",
    "            attn_scores = (query @ key.transpose(-2, -1)) * (dim_k ** -0.5)\n",
    "            attn_scores = attn_scores.masked_fill(lm_mask[:, :, :seq_len_gen, :seq_len_gen] == 0, float('-inf'))\n",
    "            attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "            attn_probs = torch.nan_to_num(attn_probs)\n",
    "            attn_out = attn_probs @ value\n",
    "            attn_out = attn_out.permute(0, 2, 1, 3).contiguous().view(batch_size_gen, seq_len_gen, hidden_size_gen)\n",
    "            attn_out = feed_forward_layers[layer_idx](attn_out)\n",
    "\n",
    "            layer_input = attn_skip + attn_out\n",
    "\n",
    "            moe_skip = layer_input\n",
    "\n",
    "            x_fp32 = layer_input.float()\n",
    "            norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "            normed_input = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "            normed_input = normed_input * rms_after_attn[layer_idx]\n",
    "\n",
    "            route_logits = router_layer[layer_idx](normed_input)\n",
    "            topk_weights, topk_indices = torch.topk(route_logits, select_experts_per_token, dim=-1)\n",
    "            topk_weights = torch.sigmoid(topk_weights)\n",
    "\n",
    "            flattened_input = normed_input.view(-1, hidden_size_gen)\n",
    "            flattened_expert_ids = topk_indices.view(-1)\n",
    "            flattened_weights = topk_weights.view(-1)\n",
    "            token_positions = torch.arange(batch_size_gen * seq_len_gen, device=device).repeat_interleave(select_experts_per_token)\n",
    "\n",
    "            expert_inputs = flattened_input[token_positions]\n",
    "            gate_up_weights = expert_feedforward_first_layer[layer_idx][flattened_expert_ids]\n",
    "            down_weights = expert_feedforward_second_layer[layer_idx][flattened_expert_ids]\n",
    "\n",
    "            up_states = torch.bmm(expert_inputs.unsqueeze(1), gate_up_weights)\n",
    "            gate_vals, up_vals = up_states.chunk(2, dim=-1)\n",
    "            activated = activation_fn(gate_vals) * up_vals\n",
    "            expert_out_flat = torch.bmm(activated, down_weights).squeeze(1)\n",
    "            scaled_expert_out = expert_out_flat * flattened_weights.unsqueeze(-1)\n",
    "\n",
    "            combined_expert_out = torch.zeros_like(flattened_input)\n",
    "            combined_expert_out.scatter_add_(\n",
    "                0, token_positions.unsqueeze(-1).expand(-1, hidden_size_gen), scaled_expert_out\n",
    "            )\n",
    "\n",
    "            shared_gate = shared_expert_layer[layer_idx](normed_input)\n",
    "            shared_up = shared_expert_feedforward_first_layer[layer_idx](normed_input)\n",
    "            shared_activated = activation_fn(shared_gate) * shared_up\n",
    "            shared_out = shared_expert_feedforward_second_layer[layer_idx](shared_activated)\n",
    "\n",
    "            moe_combined = combined_expert_out.view(batch_size_gen, seq_len_gen, hidden_size_gen)\n",
    "            final_moe_out = moe_combined + shared_out\n",
    "\n",
    "            layer_input = moe_skip + final_moe_out\n",
    "\n",
    "        x_fp32 = layer_input.float()\n",
    "        norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "        final_norm = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "        final_norm = final_norm * rms_before_final_output\n",
    "\n",
    "        vocab_logits = language_modeling_head(final_norm)\n",
    "        logits_last_step = vocab_logits[:, -1, :] \n",
    "\n",
    "        token_probs = F.softmax(logits_last_step, dim=-1)\n",
    "        sampled_token = torch.multinomial(token_probs, num_samples=1)\n",
    "\n",
    "        gen_sequence_buffer = torch.cat((gen_sequence_buffer, sampled_token), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 10, 12, 14, 11, 23, 23, 19,  0, 31, 10, 27,  0, 15, 23, 29, 22, 13,\n",
       "         14, 13,  0, 18, 22,  0, 10,  0, 13, 23, 26, 21,  0, 26, 23, 23, 21,  0,\n",
       "         10, 28,  0,  4, 10, 26, 30, 10, 26, 13,  0, 11, 33,  0,  5, 10, 26, 19,\n",
       "          0,  9, 29, 12, 19, 14, 26, 11, 14, 26, 16,  0, 10, 22, 13,  0, 17, 18,\n",
       "         27,  0, 26, 23, 23, 21, 21, 10, 28, 14, 27,  2,  0,  8, 17, 10, 28,  0,\n",
       "         11, 14, 16, 10, 22,  0, 10, 27,  0, 10,  0, 27, 21, 10, 20, 20,  0, 27,\n",
       "         23]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sequence_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook was founded in a dorm room at Harvard by Mark Zuckerberg and his roommates. What began as a small so\n"
     ]
    }
   ],
   "source": [
    "final_generated_ids = gen_sequence_buffer[0].tolist()\n",
    "\n",
    "decoded_text = ''.join([int_to_char.get(id_val, '[UNK]') for id_val in final_generated_ids])\n",
    "\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=34, bias=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = \"Dorm rooms are \" \n",
    "\n",
    "generation_limit = 100\n",
    "\n",
    "prompt_token_ids = [char_to_int[ch] for ch in prompt_text if ch in char_to_int]\n",
    "gen_sequence_buffer = torch.tensor([prompt_token_ids], dtype=torch.long, device=device)\n",
    "\n",
    "character_embedding_map.eval()\n",
    "for layer_idx in range(transformer_layers):\n",
    "    multi_head_layers[layer_idx].eval()\n",
    "    feed_forward_layers[layer_idx].eval()\n",
    "    router_layer[layer_idx].eval()\n",
    "    shared_expert_layer[layer_idx].eval()\n",
    "    shared_expert_feedforward_first_layer[layer_idx].eval()\n",
    "    shared_expert_feedforward_second_layer[layer_idx].eval()\n",
    "\n",
    "language_modeling_head.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generation loop finished.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(generation_limit):\n",
    "        \n",
    "        input_context = gen_sequence_buffer[:, -block_size:] \n",
    "        batch_size_gen, seq_len_gen = input_context.shape\n",
    "        hidden_size_gen = hidden_dim\n",
    "\n",
    "        embedded_input = character_embedding_map(input_context) \n",
    "\n",
    "        position_indices = torch.arange(seq_len_gen, device=device).unsqueeze(0)\n",
    "        inv_freq_broadcast = rope_freqs.unsqueeze(0).unsqueeze(-1).expand(batch_size_gen, -1, 1)\n",
    "        pos_ids_broadcast = position_indices.expand(batch_size_gen, -1).unsqueeze(1).float()\n",
    "        \n",
    "        with torch.autocast(device_type=device, enabled=False):\n",
    "            pos_angles = (inv_freq_broadcast.float() @ pos_ids_broadcast).transpose(1, 2)\n",
    "            rope_rotations = torch.polar(torch.ones_like(pos_angles), pos_angles)\n",
    "\n",
    "        layer_input = embedded_input\n",
    "\n",
    "        for layer_idx in range(transformer_layers):\n",
    "            attn_skip = layer_input\n",
    "\n",
    "            x_fp32 = layer_input.float()\n",
    "            norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "            normed_input = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "            normed_input = normed_input * rms_before_attn[layer_idx]\n",
    "\n",
    "            qkv_proj = multi_head_layers[layer_idx](normed_input)\n",
    "            qkv_proj = qkv_proj.view(batch_size_gen, seq_len_gen, num_heads, 3 * dim_k)\n",
    "            query, key, value = qkv_proj.chunk(3, dim=-1)\n",
    "\n",
    "            query_cmplx = torch.view_as_complex(query.float().reshape(batch_size_gen, seq_len_gen, num_heads, -1, 2))\n",
    "            key_cmplx = torch.view_as_complex(key.float().reshape(batch_size_gen, seq_len_gen, num_heads, -1, 2))\n",
    "            rope_cis_broadcast = rope_rotations.unsqueeze(2)\n",
    "            query_rot = query_cmplx * rope_cis_broadcast\n",
    "            key_rot = key_cmplx * rope_cis_broadcast\n",
    "            query = torch.view_as_real(query_rot).flatten(3).type_as(query)\n",
    "            key = torch.view_as_real(key_rot).flatten(3).type_as(key)\n",
    "\n",
    "            query = query.permute(0, 2, 1, 3)\n",
    "            key = key.permute(0, 2, 1, 3)\n",
    "            value = value.permute(0, 2, 1, 3)\n",
    "            attn_scores = (query @ key.transpose(-2, -1)) * (dim_k ** -0.5)\n",
    "            attn_scores = attn_scores.masked_fill(lm_mask[:, :, :seq_len_gen, :seq_len_gen] == 0, float('-inf'))\n",
    "            attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "            attn_probs = torch.nan_to_num(attn_probs)\n",
    "            attn_out = attn_probs @ value\n",
    "            attn_out = attn_out.permute(0, 2, 1, 3).contiguous().view(batch_size_gen, seq_len_gen, hidden_size_gen)\n",
    "            attn_out = feed_forward_layers[layer_idx](attn_out)\n",
    "\n",
    "            layer_input = attn_skip + attn_out\n",
    "\n",
    "            moe_skip = layer_input\n",
    "\n",
    "            x_fp32 = layer_input.float()\n",
    "            norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "            normed_input = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "            normed_input = normed_input * rms_after_attn[layer_idx]\n",
    "\n",
    "            route_logits = router_layer[layer_idx](normed_input)\n",
    "            topk_weights, topk_indices = torch.topk(route_logits, select_experts_per_token, dim=-1)\n",
    "            topk_weights = torch.sigmoid(topk_weights)\n",
    "\n",
    "            flattened_input = normed_input.view(-1, hidden_size_gen)\n",
    "            flattened_expert_ids = topk_indices.view(-1)\n",
    "            flattened_weights = topk_weights.view(-1)\n",
    "            token_positions = torch.arange(batch_size_gen * seq_len_gen, device=device).repeat_interleave(select_experts_per_token)\n",
    "\n",
    "            expert_inputs = flattened_input[token_positions]\n",
    "            gate_up_weights = expert_feedforward_first_layer[layer_idx][flattened_expert_ids]\n",
    "            down_weights = expert_feedforward_second_layer[layer_idx][flattened_expert_ids]\n",
    "\n",
    "            up_states = torch.bmm(expert_inputs.unsqueeze(1), gate_up_weights)\n",
    "            gate_vals, up_vals = up_states.chunk(2, dim=-1)\n",
    "            activated = activation_fn(gate_vals) * up_vals\n",
    "            expert_out_flat = torch.bmm(activated, down_weights).squeeze(1)\n",
    "            scaled_expert_out = expert_out_flat * flattened_weights.unsqueeze(-1)\n",
    "\n",
    "            combined_expert_out = torch.zeros_like(flattened_input)\n",
    "            combined_expert_out.scatter_add_(\n",
    "                0, token_positions.unsqueeze(-1).expand(-1, hidden_size_gen), scaled_expert_out\n",
    "            )\n",
    "\n",
    "            shared_gate = shared_expert_layer[layer_idx](normed_input)\n",
    "            shared_up = shared_expert_feedforward_first_layer[layer_idx](normed_input)\n",
    "            shared_activated = activation_fn(shared_gate) * shared_up\n",
    "            shared_out = shared_expert_feedforward_second_layer[layer_idx](shared_activated)\n",
    "\n",
    "            moe_combined = combined_expert_out.view(batch_size_gen, seq_len_gen, hidden_size_gen)\n",
    "            final_moe_out = moe_combined + shared_out\n",
    "\n",
    "            layer_input = moe_skip + final_moe_out\n",
    "\n",
    "        x_fp32 = layer_input.float()\n",
    "        norm_factor = torch.rsqrt(x_fp32.pow(2).mean(-1, keepdim=True) + rms_norm_eps)\n",
    "        final_norm = (x_fp32 * norm_factor).type_as(layer_input)\n",
    "        final_norm = final_norm * rms_before_final_output\n",
    "\n",
    "        vocab_logits = language_modeling_head(final_norm)\n",
    "        logits_last_step = vocab_logits[:, -1, :] \n",
    "\n",
    "        token_probs = F.softmax(logits_last_step, dim=-1)\n",
    "        sampled_token = torch.multinomial(token_probs, num_samples=1)\n",
    "\n",
    "        gen_sequence_buffer = torch.cat((gen_sequence_buffer, sampled_token), dim=1)\n",
    "\n",
    "print(\"...Generation loop finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orm rooms are t Wh began and frkerommmaterimates. beyond plat Overoon yerkermat and bey Mas aroHarvard his rkerber\n"
     ]
    }
   ],
   "source": [
    "final_generated_ids = gen_sequence_buffer[0].tolist()\n",
    "\n",
    "decoded_text = ''.join([int_to_char.get(id_val, '[UNK]') for id_val in final_generated_ids])\n",
    "\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
