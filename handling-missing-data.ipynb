{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "Handling missing data is a crucial step in the data preprocessing pipeline. Missing data can occur for various reasons, and understanding the nature of the missingness is important for choosing appropriate handling strategies. Here are some common mechanisms of missing data:\n",
    "\n",
    "**Missing Completely at Random (MCAR):**\n",
    "The missingness is completely random, and there is no relationship between the missing data and any observed or unobserved variables.\n",
    "\n",
    "**Missing at Random (MAR):**\n",
    "The missingness depends on the observed data but not on the missing data itself. In other words, the probability of missingness is the same for all units with the same observed values.\n",
    "\n",
    "**Missing Not at Random (MNAR):**\n",
    "The missingness depends on the missing values themselves, even after accounting for observed data.\n",
    "\n",
    "#### Strategies for Handling Missing Data:\n",
    "\n",
    "**Deletion:**\n",
    "- Remove rows or columns with missing values.\n",
    "- Suitable when missing data is MCAR and removing rows/columns does not introduce bias.\n",
    "Imputation:\n",
    "\n",
    "**Fill in missing values with estimated values.**\n",
    "- Common imputation methods include mean imputation, median imputation, or more sophisticated methods like k-Nearest Neighbors (KNN) imputation or regression imputation.\n",
    "\n",
    "**Advanced Techniques:**\n",
    "- Use machine learning models to predict missing values based on other features.\n",
    "- Techniques like Multiple Imputation generate multiple imputed datasets to account for uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Summary:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Impute missing values in 'Embarked' using mode imputation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m imputer_embarked \u001b[39m=\u001b[39m SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmost_frequent\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m X_train[\u001b[39m'\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m imputer_embarked\u001b[39m.\u001b[39mfit_transform(X_train[[\u001b[39m'\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m X_test[\u001b[39m'\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m imputer_embarked\u001b[39m.\u001b[39mtransform(X_test[[\u001b[39m'\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/monusingh/work-share/code-machine-learning/handling-missing-data.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Train a Random Forest classifier on the imputed training set\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/pandas/core/frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4291\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4292\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4300\u001b[0m     value, refs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4302\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4303\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4304\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4305\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4306\u001b[0m     ):\n\u001b[1;32m   4307\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4308\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/pandas/core/frame.py:5040\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5038\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   5039\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m-> 5040\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, allow_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/pandas/core/construction.py:603\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    601\u001b[0m subarr \u001b[39m=\u001b[39m data\n\u001b[1;32m    602\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m--> 603\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(data)\n\u001b[1;32m    604\u001b[0m \u001b[39melif\u001b[39;00m data\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mU\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m using_pyarrow_string_dtype():\n\u001b[1;32m    605\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/venv-dl-1.0/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1172\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mtype\u001b[39m(value))  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1171\u001b[0m     \u001b[39m# Caller is responsible\u001b[39;00m\n\u001b[0;32m-> 1172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(value\u001b[39m.\u001b[39mndim)  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(value):\n\u001b[1;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the titatnic dataset\n",
    "titanic = pd.read_csv('./data/titanic.csv')\n",
    "\n",
    "# Summary of missing values\n",
    "print('Missing Data Summary:')\n",
    "print(titanic.isnull().sum())\n",
    "\n",
    "# Drop columns with a high percentage of missing values (e.g., Cabin)\n",
    "titanic = titanic.drop(columns=['Cabin'])\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = titanic.drop(columns=['Survived'])\n",
    "y = titanic['Survived']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values in 'Age' using mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train['Age'] = imputer.fit_transform(X_train[['Age']])\n",
    "X_test['Age'] = imputer.transform(X_test[['Age']])\n",
    "\n",
    "# Impute missing values in 'Embarked' using mode imputation\n",
    "imputer_embarked = SimpleImputer(strategy='most_frequent')\n",
    "X_train['Embarked'] = imputer_embarked.fit_transform(X_train[['Embarked']])\n",
    "X_test['Embarked'] = imputer_embarked.transform(X_test[['Embarked']])\n",
    "\n",
    "# Train a Random Forest classifier on the imputed training set\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train.select_dtypes(include=['number']), y_train)\n",
    "\n",
    "# Make predictions on the imputed testing set\n",
    "y_pred = model.predict(X_test.select_dtypes(include=['number']))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dl-1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
